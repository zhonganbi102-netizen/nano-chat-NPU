#!/bin/bash

# å•NPU FineWebè®­ç»ƒ - å®Œå…¨é¿å…torchrunçŽ¯å¢ƒç»§æ‰¿é—®é¢˜
# åŸºäºŽæˆåŠŸé…ç½®çš„å•NPUç‰ˆæœ¬

set -e

echo "ðŸš€ å•NPU FineWebè®­ç»ƒ - é¿å…torchruné—®é¢˜ ðŸš€"

# 1. å¼ºåŠ›æ¸…ç†
echo "1. å¼ºåŠ›æ¸…ç†NPUçŽ¯å¢ƒ..."
./emergency_npu_cleanup.sh
sleep 15

# 2. è®¾ç½®çŽ¯å¢ƒ (å•NPU)
echo "2. è®¾ç½®å•NPUçŽ¯å¢ƒ..."

# åŠ¨æ€æŸ¥æ‰¾å¹¶è®¾ç½®çŽ¯å¢ƒ
./find_ascend_env.sh
if [ -f ".ascend_env_path" ]; then
    source .ascend_env_path
    echo "âœ… ä½¿ç”¨set_env.sh: $ASCEND_SET_ENV_PATH"
    source "$ASCEND_SET_ENV_PATH"
    export ASCEND_HOME="$(dirname "$ASCEND_SET_ENV_PATH")"
else
    echo "âš ï¸ æ‰‹åŠ¨è®¾ç½®çŽ¯å¢ƒå˜é‡..."
    export ASCEND_HOME="/usr/local/Ascend/ascend-toolkit"
    export PATH="/usr/local/Ascend/ascend-toolkit/latest/bin:$PATH"
    export LD_LIBRARY_PATH="/usr/local/Ascend/ascend-toolkit/latest/lib64:$LD_LIBRARY_PATH"
    export PYTHONPATH="/usr/local/Ascend/ascend-toolkit/latest/python/site-packages:$PYTHONPATH"
fi

# ç¡®ä¿å…³é”®è·¯å¾„
export PYTHONPATH="$ASCEND_HOME/python/site-packages:$PYTHONPATH"
export PYTHONPATH="$ASCEND_HOME/opp/built-in/op_impl/ai_core/tbe:$PYTHONPATH"
export PYTHONPATH=".:$PYTHONPATH"

# å•NPUçŽ¯å¢ƒå˜é‡
export TORCH_COMPILE_DISABLE=1
export PYTORCH_NPU_ALLOC_CONF=max_split_size_mb:128  # æ›´å¤§å†…å­˜åˆ†é…
export NPU_CALCULATE_DEVICE=0  # åªä½¿ç”¨ç¬¬ä¸€ä¸ªNPU

echo "âœ… å•NPUçŽ¯å¢ƒè®¾ç½®å®Œæˆ"

# 3. éªŒè¯çŽ¯å¢ƒ
echo "3. éªŒè¯NPUçŽ¯å¢ƒ..."
if python3 -c "import torch_npu; print('âœ… torch_npuå¯ç”¨')" 2>/dev/null; then
    echo "âœ… torch_npuéªŒè¯æˆåŠŸ"
else
    echo "âŒ torch_npuéªŒè¯å¤±è´¥"
    exit 1
fi

if python3 -c "import tbe; print('âœ… TBEæ¨¡å—å¯ç”¨')" 2>/dev/null; then
    echo "âœ… TBEéªŒè¯æˆåŠŸ"
else
    echo "âš ï¸ TBEéªŒè¯å¤±è´¥ï¼Œä½†ç»§ç»­å°è¯•..."
fi

# 4. å•NPUä¼˜åŒ–å™¨è¡¥ä¸
echo "4. åˆ›å»ºå•NPUä¼˜åŒ–å™¨è¡¥ä¸..."
cat > temp_single_npu_patch.py << 'EOF'
import torch
from nanochat.gpt import GPT

def single_npu_optimizers(self, unembedding_lr=0.001, embedding_lr=0.01, matrix_lr=0.01, weight_decay=0.0):
    print("ðŸš€ å•NPU FineWebä¼˜åŒ–å™¨: é¿å…åˆ†å¸ƒå¼å¤æ‚æ€§")
    
    # èŽ·å–æ‰€æœ‰å‚æ•°
    params = list(self.parameters())
    
    # å•ä¸€AdamWä¼˜åŒ–å™¨ï¼Œç®€åŒ–é…ç½®
    optimizer = torch.optim.AdamW(
        params, 
        lr=0.001,  # å›ºå®šå­¦ä¹ çŽ‡
        weight_decay=0.0,
        betas=(0.9, 0.95),
        eps=1e-8,
        foreach=False,  # å…³é—­foreach
        fused=False     # å…³é—­fused
    )
    
    print(f"  âœ… å•NPUä¼˜åŒ–å™¨: lr=0.001, {len(params)}ä¸ªå‚æ•°")
    return [optimizer]

# åº”ç”¨è¡¥ä¸
GPT.setup_optimizers = single_npu_optimizers
print("âœ… å•NPU FineWebä¼˜åŒ–å™¨è¡¥ä¸å·²åº”ç”¨")
EOF

# 5. è®­ç»ƒtokenizer
echo "5. è®­ç»ƒtokenizer..."
if [ ! -f ~/.cache/nanochat/tokenizer/tokenizer.pkl ]; then
    echo "è®­ç»ƒtokenizer..."
    python -m scripts.tok_train
else
    echo "âœ… tokenizerå·²å­˜åœ¨"
fi

# 6. å•NPU FineWebè®­ç»ƒ
echo ""
echo "ðŸš€ å¯åŠ¨å•NPU FineWebè®­ç»ƒ..."
echo ""
echo "ðŸ“Š è®­ç»ƒé…ç½®:"
echo "  - å•NPUè®­ç»ƒ (é¿å…åˆ†å¸ƒå¼)"
echo "  - æ¨¡åž‹æ·±åº¦: 8å±‚"
echo "  - æ‰¹æ¬¡å¤§å°: 8 (å•NPU)"
echo "  - æ€»æ‰¹æ¬¡: 16384"
echo "  - è®­ç»ƒæ­¥æ•°: 500æ­¥"
echo "  - é¢„è®¡æ—¶é—´: 15-30åˆ†é’Ÿ"
echo ""

# ç›´æŽ¥è¿è¡Œbase_train.py (æ— torchrun)
python -c "import temp_single_npu_patch" && \
python -m scripts.base_train \
    --run=single_npu_fineweb_d8 \
    --depth=8 \
    --device_batch_size=8 \
    --total_batch_size=16384 \
    --num_iterations=500 \
    --embedding_lr=0.01 \
    --unembedding_lr=0.001 \
    --matrix_lr=0.005 \
    --grad_clip=0.5 \
    --eval_every=100 \
    --sample_every=250 \
    --core_metric_every=999999

# 7. æ¸…ç†
rm -f temp_single_npu_patch.py

echo ""
echo "ðŸŽ‰ å•NPU FineWebè®­ç»ƒå®Œæˆï¼"
echo ""
echo "ðŸ“ æ¨¡åž‹ä½ç½®: ~/.cache/nanochat/base_checkpoints/single_npu_fineweb_d8/"
echo ""
echo "ðŸ”§ å¦‚æžœæˆåŠŸï¼Œå¯ä»¥è€ƒè™‘æ‰©å±•åˆ°å¤šNPUè®­ç»ƒ"
