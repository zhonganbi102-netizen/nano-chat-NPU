#!/bin/bash

# Muonä¼˜åŒ–å™¨è¯Šæ–­è„šæœ¬
# Muon optimizer diagnostic script

echo "ðŸ”¬ Muonä¼˜åŒ–å™¨è¯Šæ–­å·¥å…·"
echo ""

# 1. çŽ¯å¢ƒå‡†å¤‡
source /usr/local/Ascend/ascend-toolkit/set_env.sh
export ASCEND_RT_VISIBLE_DEVICES=0
export PYTORCH_NPU_ALLOC_CONF=max_split_size_mb:32
export NPU_COMPILE_DISABLE=1

# 2. åˆ›å»ºè¯Šæ–­è„šæœ¬
cat > diagnose_muon.py << 'EOF'
"""
Muonä¼˜åŒ–å™¨è¯Šæ–­è„šæœ¬
"""
import os
import sys
import time
import torch
import torch_npu
import gc

def test_basic_npu():
    """æµ‹è¯•åŸºç¡€NPUåŠŸèƒ½"""
    print("ðŸ” æµ‹è¯•1: åŸºç¡€NPUåŠŸèƒ½...")
    
    if not torch_npu.npu.is_available():
        print("âŒ NPUä¸å¯ç”¨")
        return False
    
    torch_npu.npu.set_device(0)
    print(f"âœ… ä½¿ç”¨è®¾å¤‡: npu:{torch_npu.npu.current_device()}")
    
    # ç®€å•å¼ é‡æµ‹è¯•
    x = torch.randn(10, 10).to('npu:0')
    y = torch.matmul(x, x.T)
    result = y.sum().item()
    print(f"âœ… çŸ©é˜µè¿ç®—æµ‹è¯•: {result:.2f}")
    
    return True

def test_model_creation():
    """æµ‹è¯•æ¨¡åž‹åˆ›å»º"""
    print("\nðŸ” æµ‹è¯•2: æ¨¡åž‹åˆ›å»º...")
    
    try:
        # å¯¼å…¥nanochatæ¨¡å—
        sys.path.append('.')
        from nanochat.gpt import GPT
        from nanochat.common import ModelConfig
        
        # åˆ›å»ºæœ€å°é…ç½®
        config = ModelConfig(
            vocab_size=100,
            seq_len=128,
            depth=2,
            model_dim=64,
            num_heads=2,
            num_kv_heads=2
        )
        
        print(f"é…ç½®: {config}")
        
        # åˆ›å»ºæ¨¡åž‹
        model = GPT(config)
        model = model.to('npu:0')
        
        print("âœ… æ¨¡åž‹åˆ›å»ºæˆåŠŸ")
        return model, config
        
    except Exception as e:
        print(f"âŒ æ¨¡åž‹åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, None

def test_muon_optimizer(model):
    """æµ‹è¯•Muonä¼˜åŒ–å™¨"""
    print("\nðŸ” æµ‹è¯•3: Muonä¼˜åŒ–å™¨...")
    
    if model is None:
        print("âŒ æ¨¡åž‹ä¸ºç©ºï¼Œè·³è¿‡ä¼˜åŒ–å™¨æµ‹è¯•")
        return False
    
    try:
        from nanochat.muon import Muon
        
        print("æ­£åœ¨åˆ›å»ºMuonä¼˜åŒ–å™¨...")
        
        # èŽ·å–å‚æ•°
        params = list(model.parameters())
        print(f"æ¨¡åž‹å‚æ•°æ•°é‡: {len(params)}")
        
        # æ˜¾ç¤ºå‚æ•°å½¢çŠ¶
        for i, p in enumerate(params[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"  å‚æ•°{i}: {p.shape}, device: {p.device}")
        
        print("åˆ›å»ºMuonä¼˜åŒ–å™¨ä¸­...")
        start_time = time.time()
        
        # åˆ›å»ºä¼˜åŒ–å™¨ï¼ˆè¿™é‡Œå¯èƒ½ä¼šå¡ä½ï¼‰
        optimizer = Muon(params, lr=0.001)
        
        end_time = time.time()
        print(f"âœ… Muonä¼˜åŒ–å™¨åˆ›å»ºæˆåŠŸï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
        
        return True
        
    except Exception as e:
        print(f"âŒ Muonä¼˜åŒ–å™¨åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_alternative_optimizer(model):
    """æµ‹è¯•æ›¿ä»£ä¼˜åŒ–å™¨"""
    print("\nðŸ” æµ‹è¯•4: æ›¿ä»£ä¼˜åŒ–å™¨...")
    
    if model is None:
        print("âŒ æ¨¡åž‹ä¸ºç©ºï¼Œè·³è¿‡")
        return False
    
    try:
        # æµ‹è¯•AdamW
        optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)
        print("âœ… AdamWä¼˜åŒ–å™¨åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•ä¸€æ­¥ä¼˜åŒ–
        x = torch.randint(0, 100, (2, 64)).to('npu:0')
        y = model(x)
        loss = y.mean()
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        
        print("âœ… ä¼˜åŒ–æ­¥éª¤æµ‹è¯•æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ æ›¿ä»£ä¼˜åŒ–å™¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    print("å¼€å§‹Muonä¼˜åŒ–å™¨è¯Šæ–­...\n")
    
    # æ¸…ç†çŽ¯å¢ƒ
    if torch_npu.npu.is_available():
        torch_npu.npu.empty_cache()
        gc.collect()
    
    # è¿è¡Œæµ‹è¯•
    if not test_basic_npu():
        return
    
    model, config = test_model_creation()
    
    # æµ‹è¯•Muonï¼ˆå¯èƒ½å¡ä½çš„åœ°æ–¹ï¼‰
    print("\nâš ï¸  å³å°†æµ‹è¯•Muonä¼˜åŒ–å™¨ï¼Œå¦‚æžœå¡ä½è¯·Ctrl+Cç»ˆæ­¢")
    time.sleep(2)
    
    muon_success = test_muon_optimizer(model)
    
    if not muon_success:
        print("\nðŸ”„ Muonå¤±è´¥ï¼Œæµ‹è¯•æ›¿ä»£æ–¹æ¡ˆ...")
        test_alternative_optimizer(model)
    
    print("\nðŸŽ¯ è¯Šæ–­æ€»ç»“:")
    print(f"  - åŸºç¡€NPU: âœ…")
    print(f"  - æ¨¡åž‹åˆ›å»º: {'âœ…' if model is not None else 'âŒ'}")
    print(f"  - Muonä¼˜åŒ–å™¨: {'âœ…' if muon_success else 'âŒ'}")
    print(f"  - æ›¿ä»£æ–¹æ¡ˆ: å¯ç”¨")

if __name__ == "__main__":
    main()
EOF

# 3. è¿è¡Œè¯Šæ–­
echo "3. è¿è¡ŒMuonä¼˜åŒ–å™¨è¯Šæ–­..."
echo "å¦‚æžœç¨‹åºå¡ä½ï¼Œè¯·æŒ‰Ctrl+Cç»ˆæ­¢"
echo ""

python3 diagnose_muon.py

# 4. æ¸…ç†
rm -f diagnose_muon.py

echo ""
echo "ðŸŽ‰ è¯Šæ–­å®Œæˆï¼"