#!/bin/bash

# ä¿å®ˆå•NPUè®­ç»ƒ - è§£å†³Muonä¼˜åŒ–å™¨å¡æ­»é—®é¢˜
# Conservative single NPU training - fix Muon optimizer hanging

set -e

echo "ðŸ›¡ï¸  ä¿å®ˆå•NPUè®­ç»ƒ - è§£å†³Muonä¼˜åŒ–å™¨é—®é¢˜"
echo ""

# 1. çŽ¯å¢ƒè®¾ç½®
echo "1. è®¾ç½®NPUçŽ¯å¢ƒ..."
source /usr/local/Ascend/ascend-toolkit/set_env.sh

# ä¸¥æ ¼çš„å•NPUè®¾ç½®
export ASCEND_RT_VISIBLE_DEVICES=0
export WORLD_SIZE=1
export RANK=0
export LOCAL_RANK=0
export MASTER_ADDR=127.0.0.1
export MASTER_PORT=29700

# å†…å­˜å’Œç¼–è¯‘ä¼˜åŒ–
export PYTORCH_NPU_ALLOC_CONF=max_split_size_mb:64  # NPUæœ€å°è¦æ±‚>20MB
export NPU_COMPILE_DISABLE=1
export TORCH_NPU_DISABLE_LAZY_INIT=1

# Pythonä¼˜åŒ–
export PYTHONUNBUFFERED=1
export OMP_NUM_THREADS=1

echo "âœ… çŽ¯å¢ƒé…ç½®å®Œæˆ"

# 2. å½»åº•æ¸…ç†
echo ""
echo "2. å½»åº•æ¸…ç†çŽ¯å¢ƒ..."
pkill -f "python.*train" || true
pkill -f "torchrun" || true
sleep 2

python3 -c "
import torch
import torch_npu
import gc
import time

print('æ¸…ç†NPUå†…å­˜...')
if torch_npu.npu.is_available():
    for i in range(torch_npu.npu.device_count()):
        torch_npu.npu.set_device(i)
        torch_npu.npu.empty_cache()
        torch_npu.npu.synchronize()
    
    # ç­‰å¾…æ¸…ç†å®Œæˆ
    time.sleep(1)
    gc.collect()
    time.sleep(1)
    
    print(f'âœ… å·²æ¸…ç† {torch_npu.npu.device_count()} ä¸ªNPUè®¾å¤‡')
"

# 3. æ£€æŸ¥åŸºç¡€çŽ¯å¢ƒ
echo ""
echo "3. æ£€æŸ¥åŸºç¡€çŽ¯å¢ƒ..."
python3 -c "
import torch
import torch_npu
import sys

print(f'Pythonç‰ˆæœ¬: {sys.version}')
print(f'PyTorchç‰ˆæœ¬: {torch.__version__}')
print(f'torch_npuç‰ˆæœ¬: {torch_npu.__version__}')
print(f'NPUå¯ç”¨: {torch_npu.npu.is_available()}')
print(f'NPUè®¾å¤‡æ•°: {torch_npu.npu.device_count()}')

if torch_npu.npu.is_available():
    torch_npu.npu.set_device(0)
    print(f'å½“å‰è®¾å¤‡: npu:{torch_npu.npu.current_device()}')
    
    # æµ‹è¯•ç®€å•å¼ é‡æ“ä½œ
    x = torch.randn(2, 2).to('npu:0')
    y = x + 1
    print(f'å¼ é‡æµ‹è¯•: {y.sum().item():.2f}')
    print('âœ… NPUåŸºç¡€åŠŸèƒ½æ­£å¸¸')
"

# 4. ä¿å®ˆè®­ç»ƒå‚æ•°
echo ""
echo "4. å¼€å§‹ä¿å®ˆè®­ç»ƒ..."
echo "ä½¿ç”¨æœ€å°å¯è¡Œå‚æ•°é¿å…Muonå¡æ­»..."

# åˆ›å»ºè®­ç»ƒå¯åŠ¨è„šæœ¬
cat > temp_conservative_train.py << 'EOF'
import os
import sys
import time
import torch
import torch_npu

# è®¾ç½®NPUè®¾å¤‡
if torch_npu.npu.is_available():
    torch_npu.npu.set_device(0)
    print(f"ä½¿ç”¨è®¾å¤‡: npu:{torch_npu.npu.current_device()}")

# å¯¼å…¥è®­ç»ƒè„šæœ¬
sys.path.append('.')
from scripts.base_train import main

if __name__ == "__main__":
    print("ðŸš€ å¼€å§‹ä¿å®ˆå•NPUè®­ç»ƒ...")
    
    # è®¾ç½®æœ€ä¿å®ˆçš„å‚æ•°
    sys.argv = [
        'base_train.py',
        '--run=conservative_single_npu',
        '--depth=4',                    # æžå°æ·±åº¦
        '--device_batch_size=1',        # æœ€å°batch
        '--total_batch_size=2',         # æœ€å°æ€»batch
        '--num_iterations=20',          # å°‘é‡è¿­ä»£
        '--embedding_lr=0.0001',        # æžå°å­¦ä¹ çŽ‡
        '--unembedding_lr=0.00001',
        '--matrix_lr=0.00005',
        '--grad_clip=1.0',
        '--eval_every=10',
        '--sample_every=999999',
        '--core_metric_every=999999',
        '--verbose'
    ]
    
    try:
        main()
        print("âœ… ä¿å®ˆè®­ç»ƒæˆåŠŸå®Œæˆï¼")
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
EOF

# æ‰§è¡Œä¿å®ˆè®­ç»ƒ
python3 temp_conservative_train.py

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
rm -f temp_conservative_train.py

echo ""
echo "ðŸŽ‰ ä¿å®ˆå•NPUè®­ç»ƒå®Œæˆï¼"
echo ""
echo "å¦‚æžœæˆåŠŸï¼Œå¯ä»¥å°è¯•å¢žåŠ å‚æ•°ï¼š"
echo "  - depth: 4 -> 6 -> 8"
echo "  - device_batch_size: 1 -> 2 -> 4"
echo "  - num_iterations: 20 -> 100 -> 1000"