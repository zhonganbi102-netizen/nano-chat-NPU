#!/bin/bash

echo "=== ç®€åŒ–è°ƒè¯•è®­ç»ƒï¼ˆä¿®æ”¹è„šæœ¬å‚æ•°ï¼‰==="

# æ¸…ç†ç¯å¢ƒ
source clean_npu_environment.sh

# è®¾ç½®å•NPUç¯å¢ƒ
export WORLD_SIZE=1
export RANK=0
export LOCAL_RANK=0
export MASTER_ADDR=localhost
export MASTER_PORT=12345
export ASCEND_RT_VISIBLE_DEVICES=0

cd /mnt/linxid615/bza/nanochat-npu

echo "åˆ›å»ºä¸´æ—¶è°ƒè¯•è®­ç»ƒè„šæœ¬..."

# åˆ›å»ºä¸´æ—¶çš„è°ƒè¯•è®­ç»ƒè„šæœ¬
cat > debug_train_temp.py << 'EOF'
"""
ä¸´æ—¶è°ƒè¯•è®­ç»ƒè„šæœ¬ - åŸºäºbase_train.pyçš„ç®€åŒ–ç‰ˆæœ¬
"""

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
import time
import wandb
import torch
import torch_npu  # NPUæ”¯æŒ

from nanochat.gpt import GPT, GPTConfig
from nanochat.dataloader import tokenizing_distributed_data_loader
from nanochat.common import compute_init, compute_cleanup, print0, DummyWandb, print_banner, get_base_dir
from nanochat.tokenizer import get_tokenizer, get_token_bytes

print_banner()

# è°ƒè¯•è®¾ç½®ï¼ˆç›´æ¥ä¿®æ”¹ï¼Œé¿å…configuratoré—®é¢˜ï¼‰
run = "debug_npu"
depth = 2  # å°æ¨¡å‹
max_seq_len = 256  # çŸ­åºåˆ—
num_iterations = 3  # åªè®­ç»ƒ3æ­¥
device_batch_size = 2  # å°æ‰¹æ¬¡
total_batch_size = 1024  # å°æ€»æ‰¹æ¬¡
embedding_lr = 0.01
unembedding_lr = 0.002
weight_decay = 0.01
matrix_lr = 0.01
grad_clip = 1.0
eval_every = 3  # æ¯3æ­¥è¯„ä¼°
eval_tokens = 2048  # å°‘é‡è¯„ä¼°token
core_metric_every = 10  # è·³è¿‡core metric
core_metric_max_per_task = 10
sample_every = 10  # è·³è¿‡sampling
model_tag = "debug_npu"

print("=== è°ƒè¯•è®­ç»ƒè®¾ç½® ===")
print(f"æ·±åº¦: {depth}, åºåˆ—é•¿åº¦: {max_seq_len}")
print(f"æ‰¹æ¬¡å¤§å°: {device_batch_size}, æ€»æ‰¹æ¬¡: {total_batch_size}")
print(f"è®­ç»ƒæ­¥æ•°: {num_iterations}")

# Compute init
ddp, ddp_rank, ddp_local_rank, ddp_world_size, device = compute_init()
master_process = ddp_rank == 0
device_type = "npu" if device.type == "npu" else "cuda"
autocast_ctx = torch.amp.autocast(device_type=device_type, dtype=torch.bfloat16)

print0(f"è®¾å¤‡ç±»å‹: {device_type}, è®¾å¤‡: {device}")

# wandb logging init
use_dummy_wandb = True  # è°ƒè¯•æ—¶ä¸ç”¨wandb
wandb_run = DummyWandb()

# Tokenizer
tokenizer = get_tokenizer()
token_bytes = get_token_bytes(device=device)
vocab_size = tokenizer.get_vocab_size()
print0(f"è¯æ±‡è¡¨å¤§å°: {vocab_size:,}")

# Model kwargs
num_layers = depth
model_dim = depth * 64
num_heads = max(1, (model_dim + 127) // 128)
num_kv_heads = num_heads
print0(f"æ¨¡å‹å±‚æ•°: {num_layers}, ç»´åº¦: {model_dim}, å¤´æ•°: {num_heads}")

# è®¡ç®—æ¢¯åº¦ç´¯ç§¯
tokens_per_fwdbwd = device_batch_size * max_seq_len
world_tokens_per_fwdbwd = tokens_per_fwdbwd * ddp_world_size
assert total_batch_size % world_tokens_per_fwdbwd == 0
grad_accum_steps = total_batch_size // world_tokens_per_fwdbwd
print0(f"æ¢¯åº¦ç´¯ç§¯æ­¥æ•°: {grad_accum_steps}")

# åˆå§‹åŒ–æ¨¡å‹
model_config_kwargs = dict(
    sequence_len=max_seq_len, 
    vocab_size=vocab_size, 
    n_layer=num_layers, 
    n_head=num_heads, 
    n_kv_head=num_kv_heads, 
    n_embd=model_dim
)

with torch.device("meta"):
    model_config = GPTConfig(**model_config_kwargs)
    model = GPT(model_config)

model.to_empty(device=device)
model.init_weights()
orig_model = model

# NPUå…¼å®¹æ€§ï¼šè·³è¿‡ç¼–è¯‘
if device_type == "npu":
    print0("NPUç¯å¢ƒï¼šè·³è¿‡torch.compile")
else:
    model = torch.compile(model, dynamic=False)

num_params = sum(p.numel() for p in model.parameters())
print0(f"å‚æ•°æ•°é‡: {num_params:,}")

# åˆå§‹åŒ–ä¼˜åŒ–å™¨
optimizers = model.setup_optimizers(
    unembedding_lr=unembedding_lr, 
    embedding_lr=embedding_lr, 
    matrix_lr=matrix_lr, 
    weight_decay=weight_decay
)
adamw_optimizer, muon_optimizer = optimizers
print0("âœ… ä¼˜åŒ–å™¨åˆå§‹åŒ–æˆåŠŸ")

# æ•°æ®åŠ è½½å™¨
base_dir = get_base_dir()
print0(f"Baseç›®å½•: {base_dir}")

try:
    print0("å°è¯•åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨...")
    train_loader = tokenizing_distributed_data_loader(device_batch_size, max_seq_len, split="train")
    print0("æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸï¼Œå°è¯•è·å–ç¬¬ä¸€æ‰¹æ•°æ®...")
    
    # ä½¿ç”¨è¶…æ—¶æœºåˆ¶é¿å…æ— é™ç­‰å¾…
    import signal
    class TimeoutError(Exception):
        pass
    
    def timeout_handler(signum, frame):
        raise TimeoutError("æ•°æ®åŠ è½½è¶…æ—¶")
    
    signal.signal(signal.SIGALRM, timeout_handler)
    signal.alarm(10)  # 10ç§’è¶…æ—¶
    
    try:
        x, y = next(train_loader)
        signal.alarm(0)  # å–æ¶ˆè¶…æ—¶
        print0("âœ… æ•°æ®åŠ è½½å™¨æˆåŠŸ")
        use_real_data = True
    except TimeoutError:
        signal.alarm(0)
        print0("âš ï¸  æ•°æ®åŠ è½½è¶…æ—¶ï¼Œåˆ‡æ¢åˆ°æ¨¡æ‹Ÿæ•°æ®")
        use_real_data = False
    except Exception as e:
        signal.alarm(0)
        print0(f"âš ï¸  æ•°æ®åŠ è½½å™¨å¼‚å¸¸: {e}")
        use_real_data = False
        
except Exception as e:
    print0(f"âš ï¸  æ•°æ®åŠ è½½å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
    print0("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
    use_real_data = False

print0("\n=== å¼€å§‹è°ƒè¯•è®­ç»ƒ ===")

# è®­ç»ƒå¾ªç¯
for step in range(num_iterations + 1):
    last_step = step == num_iterations
    
    if last_step:
        print0(f"âœ… è°ƒè¯•è®­ç»ƒå®Œæˆï¼æ€»å…±{num_iterations}æ­¥")
        break
    
    print0(f"\næ­¥éª¤ {step + 1}/{num_iterations}")
    
    # åŒæ­¥è®¡æ—¶
    if device_type == "npu":
        torch_npu.npu.synchronize()
    else:
        torch.cuda.synchronize()
    t0 = time.time()
    
    # æ¢¯åº¦ç´¯ç§¯
    for micro_step in range(grad_accum_steps):
        if use_real_data:
            try:
                if micro_step == 0:  # åªåœ¨ç¬¬ä¸€ä¸ªmicro stepè·å–æ•°æ®
                    pass  # x, y å·²ç»ä»ä¹‹å‰åŠ è½½
                else:
                    x, y = next(train_loader)
            except:
                # å¦‚æœæ•°æ®è€—å°½ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
                x = torch.randint(0, vocab_size, (device_batch_size, max_seq_len), device=device)
                y = torch.randint(0, vocab_size, (device_batch_size, max_seq_len), device=device)
        else:
            # æ¨¡æ‹Ÿæ•°æ®
            x = torch.randint(0, vocab_size, (device_batch_size, max_seq_len), device=device)
            y = torch.randint(0, vocab_size, (device_batch_size, max_seq_len), device=device)
        
        with autocast_ctx:
            loss = model(x, y)
        
        train_loss = loss.detach()
        loss = loss / grad_accum_steps
        loss.backward()
        
        if use_real_data and micro_step < grad_accum_steps - 1:
            try:
                x, y = next(train_loader)  # é¢„å–ä¸‹ä¸€æ‰¹
            except:
                pass
    
    # æ¢¯åº¦è£å‰ª
    if grad_clip > 0.0:
        torch.nn.utils.clip_grad_norm_(orig_model.parameters(), grad_clip)
    
    # ä¼˜åŒ–å™¨æ­¥éª¤
    for opt in optimizers:
        opt.step()
    model.zero_grad(set_to_none=True)
    
    # è®¡æ—¶
    if device_type == "npu":
        torch_npu.npu.synchronize()
    else:
        torch.cuda.synchronize()
    t1 = time.time()
    dt = t1 - t0
    
    # ç»Ÿè®¡
    tokens_per_sec = int(world_tokens_per_fwdbwd / dt)
    print0(f"  æŸå¤±: {train_loss.item():.4f}")
    print0(f"  æ—¶é—´: {dt*1000:.1f}ms")
    print0(f"  é€Ÿåº¦: {tokens_per_sec:,} tokens/sec")
    
    if device_type == "npu":
        mem_mb = torch_npu.npu.memory_allocated(0) / 1024**2
    else:
        mem_mb = torch.cuda.memory_allocated(0) / 1024**2
    print0(f"  å†…å­˜: {mem_mb:.1f}MB")

# æ¸…ç†
wandb_run.finish()
compute_cleanup()

print0("\nğŸ‰ è°ƒè¯•è®­ç»ƒæˆåŠŸå®Œæˆï¼")
EOF

echo "è¿è¡Œä¸´æ—¶è°ƒè¯•è®­ç»ƒè„šæœ¬..."
python3 debug_train_temp.py

echo "æ¸…ç†ä¸´æ—¶æ–‡ä»¶..."
rm -f debug_train_temp.py

echo "è°ƒè¯•å®Œæˆ"