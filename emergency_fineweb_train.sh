#!/bin/bash

# ç´§æ€¥FineWebè®­ç»ƒè„šæœ¬ - åŸºäºŽæˆåŠŸçš„manual_4npu_train.shé…ç½®
# ä¸“é—¨è§£å†³TBEæ¨¡å—çŽ¯å¢ƒç»§æ‰¿é—®é¢˜

set -e

echo "ðŸš¨ ç´§æ€¥FineWebè®­ç»ƒ - åŸºäºŽæˆåŠŸé…ç½® ðŸš¨"

# 1. å¼ºåŠ›æ¸…ç†
echo "1. å¼ºåŠ›æ¸…ç†NPUçŽ¯å¢ƒ..."
./emergency_npu_cleanup.sh
sleep 20  # æ›´é•¿ç­‰å¾…æ—¶é—´

# 2. å®Œæ•´çŽ¯å¢ƒè®¾ç½® (åŸºäºŽæˆåŠŸé…ç½®)
echo "2. è®¾ç½®å®Œæ•´NPUçŽ¯å¢ƒ..."

# åŠ¨æ€æŸ¥æ‰¾set_env.sh
echo "ðŸ” æŸ¥æ‰¾set_env.shæ–‡ä»¶..."
./find_ascend_env.sh
if [ -f ".ascend_env_path" ]; then
    source .ascend_env_path
    echo "âœ… æ‰¾åˆ°set_env.sh: $ASCEND_SET_ENV_PATH"
    source "$ASCEND_SET_ENV_PATH"
    
    # ä»Žset_env.shè·¯å¾„æŽ¨æ–­ASCEND_HOME
    export ASCEND_HOME="$(dirname "$ASCEND_SET_ENV_PATH")"
    echo "âœ… ASCEND_HOME: $ASCEND_HOME"
else
    echo "âŒ æ‰¾ä¸åˆ°set_env.shï¼Œæ‰‹åŠ¨è®¾ç½®çŽ¯å¢ƒ..."
    # æ‰‹åŠ¨è®¾ç½®åŸºæœ¬çŽ¯å¢ƒå˜é‡
    export ASCEND_HOME="/usr/local/Ascend/ascend-toolkit"
    export PATH="/usr/local/Ascend/ascend-toolkit/latest/bin:$PATH"
    export LD_LIBRARY_PATH="/usr/local/Ascend/ascend-toolkit/latest/lib64:$LD_LIBRARY_PATH"
    export PYTHONPATH="/usr/local/Ascend/ascend-toolkit/latest/python/site-packages:$PYTHONPATH"
fi

# æ˜¾å¼è®¾ç½®å…³é”®è·¯å¾„
export PYTHONPATH="$ASCEND_HOME/python/site-packages:$PYTHONPATH"
export PYTHONPATH="$ASCEND_HOME/opp/built-in/op_impl/ai_core/tbe:$PYTHONPATH"
export PYTHONPATH=".:$PYTHONPATH"
export LD_LIBRARY_PATH="$ASCEND_HOME/lib64:$LD_LIBRARY_PATH"

# åˆ†å¸ƒå¼è®­ç»ƒçŽ¯å¢ƒå˜é‡
export WORLD_SIZE=4
export MASTER_ADDR=127.0.0.1
export MASTER_PORT=29524
export TORCH_COMPILE_DISABLE=1
export PYTORCH_NPU_ALLOC_CONF=max_split_size_mb:64
export HCCL_WHITELIST_DISABLE=1
export HCCL_IF_IP=127.0.0.1

echo "âœ… çŽ¯å¢ƒå˜é‡è®¾ç½®å®Œæˆ"

# 3. éªŒè¯TBEæ¨¡å—
echo "3. éªŒè¯TBEæ¨¡å—..."
if python3 -c "import tbe; print('âœ… TBEæ¨¡å—å¯ç”¨')" 2>/dev/null; then
    echo "âœ… TBEéªŒè¯æˆåŠŸ"
else
    echo "âŒ TBEéªŒè¯å¤±è´¥ï¼Œä½†ç»§ç»­å°è¯•..."
fi

# 4. åŸºäºŽæˆåŠŸé…ç½®çš„ä¼˜åŒ–å™¨è¡¥ä¸
echo "4. åˆ›å»ºç´§æ€¥ä¼˜åŒ–å™¨è¡¥ä¸..."
cat > temp_emergency_patch.py << 'EOF'
import torch
from nanochat.gpt import GPT

def emergency_optimizers(self, unembedding_lr=0.001, embedding_lr=0.01, matrix_lr=0.01, weight_decay=0.0):
    print("ðŸš¨ ç´§æ€¥FineWebè®­ç»ƒä¼˜åŒ–å™¨: åŸºäºŽmanual_4npuæˆåŠŸé…ç½®")
    
    # èŽ·å–æ‰€æœ‰å‚æ•°
    embedding_params = [p for n, p in self.named_parameters() if 'emb_tok' in n]
    other_params = [p for n, p in self.named_parameters() if 'emb_tok' not in n]
    
    opts = []
    
    # åµŒå…¥å±‚ä¼˜åŒ–å™¨ (ä¿å®ˆé…ç½®)
    if embedding_params:
        embedding_opt = torch.optim.AdamW(
            [{'params': embedding_params, 'lr': embedding_lr*0.4, 'initial_lr': embedding_lr*0.4}], 
            lr=embedding_lr*0.4, 
            weight_decay=weight_decay, 
            betas=(0.9, 0.95),
            eps=1e-8,
            foreach=False,
            fused=False
        )
        opts.append(embedding_opt)
        print(f"  âœ… åµŒå…¥å±‚ä¼˜åŒ–å™¨: lr={embedding_lr*0.4:.6f}")
    
    # å…¶ä»–å‚æ•°ä¼˜åŒ–å™¨
    if other_params:
        other_opt = torch.optim.AdamW(
            [{'params': other_params, 'lr': matrix_lr*0.4, 'initial_lr': matrix_lr*0.4}], 
            lr=matrix_lr*0.4, 
            weight_decay=0.0, 
            betas=(0.9, 0.95),
            eps=1e-8,
            foreach=False,
            fused=False
        )
        opts.append(other_opt)
        print(f"  âœ… å…¶ä»–å‚æ•°ä¼˜åŒ–å™¨: lr={matrix_lr*0.4:.6f}")
    
    print(f"  âœ… æ€»å…± {len(opts)} ä¸ªä¼˜åŒ–å™¨")
    return opts

# åº”ç”¨è¡¥ä¸
GPT.setup_optimizers = emergency_optimizers
print("âœ… ç´§æ€¥FineWebä¼˜åŒ–å™¨è¡¥ä¸å·²åº”ç”¨")
EOF

# 5. è®­ç»ƒtokenizer
echo "5. è®­ç»ƒtokenizer..."
if [ ! -f ~/.cache/nanochat/tokenizer/tokenizer.pkl ]; then
    echo "è®­ç»ƒtokenizer..."
    python -m scripts.tok_train
else
    echo "âœ… tokenizerå·²å­˜åœ¨"
fi

# 6. å¯åŠ¨ç´§æ€¥FineWebè®­ç»ƒ (åŸºäºŽmanualæˆåŠŸé…ç½®)
echo ""
echo "ðŸš€ å¯åŠ¨ç´§æ€¥FineWebè®­ç»ƒ..."
echo ""
echo "ðŸ“Š è®­ç»ƒé…ç½®:"
echo "  - åŸºäºŽ: manual_4npu_train.sh æˆåŠŸé…ç½®"
echo "  - æ¨¡åž‹æ·±åº¦: 8å±‚"
echo "  - æ‰¹æ¬¡å¤§å°: æ¯è®¾å¤‡2, æ€»32768 (ä¿å®ˆå†…å­˜)"
echo "  - è®­ç»ƒæ­¥æ•°: 1000æ­¥"
echo "  - çŽ¯å¢ƒ: å®Œæ•´TBEè·¯å¾„è®¾ç½®"
echo "  - é¢„è®¡æ—¶é—´: 30-60åˆ†é’Ÿ"
echo ""

# æ˜¾å¼å¯¼å…¥è¡¥ä¸å¹¶å¯åŠ¨è®­ç»ƒ
python -c "import temp_emergency_patch" && \
PYTHONPATH="$ASCEND_HOME/python/site-packages:$ASCEND_HOME/opp/built-in/op_impl/ai_core/tbe:." torchrun --nproc_per_node=4 \
    --master_addr=127.0.0.1 \
    --master_port=29524 \
    scripts/base_train.py \
    --model_tag=emergency_fineweb_d8 \
    --depth=8 \
    --device_batch_size=2 \
    --total_batch_size=32768 \
    --num_iterations=1000 \
    --embedding_lr=0.005 \
    --unembedding_lr=0.0005 \
    --matrix_lr=0.0025 \
    --grad_clip=0.5 \
    --eval_every=100 \
    --sample_every=500 \
    --core_metric_every=999999

# 7. æ¸…ç†
rm -f temp_emergency_patch.py

echo ""
echo "ðŸŽ‰ ç´§æ€¥FineWebè®­ç»ƒå®Œæˆï¼"
echo ""
echo "ðŸ“ æ¨¡åž‹ä½ç½®: ~/.cache/nanochat/base_checkpoints/emergency_fineweb_d8/"
echo ""
echo "ðŸ”§ å¦‚æžœæˆåŠŸï¼Œå¯ä»¥åŸºäºŽæ­¤é…ç½®è¿›è¡Œæ›´å¤§è§„æ¨¡è®­ç»ƒ"
