#!/bin/bash

echo "=== ğŸš€ FineWeb å®Œæ•´æ•°æ®é›†ä¸‹è½½è„šæœ¬ ==="
echo "è­¦å‘Šï¼šè¿™å°†ä¸‹è½½çº¦1TBçš„æ•°æ®ï¼ˆ1823ä¸ªæ–‡ä»¶ï¼‰"
echo "ç¡®ä¿ä½ æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´å’Œæ—¶é—´ï¼"

# è®¾ç½®åŸºæœ¬å‚æ•°
export HF_ENDPOINT=https://hf-mirror.com
BASE_DATA_DIR="./base_data"
TOTAL_FILES=1823  # 0-1822
BATCH_SIZE=10     # æ¯æ‰¹ä¸‹è½½10ä¸ªæ–‡ä»¶
LOG_FILE="download.log"

echo "é•œåƒæº: $HF_ENDPOINT"
echo "ç›®æ ‡ç›®å½•: $BASE_DATA_DIR"
echo "æ€»æ–‡ä»¶æ•°: $TOTAL_FILES"
echo "æ—¥å¿—æ–‡ä»¶: $LOG_FILE"

# åˆ›å»ºç›®å½•
mkdir -p "$BASE_DATA_DIR"

# æ£€æŸ¥å·²ä¸‹è½½æ–‡ä»¶
existing_files=$(ls "$BASE_DATA_DIR"/*.parquet 2>/dev/null | wc -l)
echo "å·²ä¸‹è½½æ–‡ä»¶: $existing_files"

# ç¡®è®¤ä¸‹è½½
echo ""
echo "ä¸‹è½½é€‰é¡¹:"
echo "1) å¿«é€Ÿæ¨¡å¼ï¼šå¹¶è¡Œä¸‹è½½ï¼Œé€Ÿåº¦å¿«ä½†å ç”¨å¸¦å®½å¤§"
echo "2) ç¨³å®šæ¨¡å¼ï¼šé€ä¸ªä¸‹è½½ï¼Œç¨³å®šä½†è¾ƒæ…¢" 
echo "3) æ–­ç‚¹ç»­ä¼ ï¼šä»ä¸Šæ¬¡ä¸­æ–­å¤„ç»§ç»­"
echo "4) è‡ªå®šä¹‰èŒƒå›´ï¼šæŒ‡å®šä¸‹è½½æ–‡ä»¶èŒƒå›´"
echo "5) é€€å‡º"

read -p "è¯·é€‰æ‹©æ¨¡å¼ (1-5): " mode

case $mode in
    1)
        echo "=== å¿«é€Ÿå¹¶è¡Œä¸‹è½½æ¨¡å¼ ==="
        PARALLEL_JOBS=5
        ;;
    2)
        echo "=== ç¨³å®šé€ä¸ªä¸‹è½½æ¨¡å¼ ==="
        PARALLEL_JOBS=1
        ;;
    3)
        echo "=== æ–­ç‚¹ç»­ä¼ æ¨¡å¼ ==="
        PARALLEL_JOBS=3
        ;;
    4)
        echo "=== è‡ªå®šä¹‰èŒƒå›´æ¨¡å¼ ==="
        read -p "èµ·å§‹æ–‡ä»¶ç¼–å· (0-1822): " START_NUM
        read -p "ç»“æŸæ–‡ä»¶ç¼–å· (0-1822): " END_NUM
        read -p "å¹¶è¡Œä»»åŠ¡æ•° (1-10): " PARALLEL_JOBS
        TOTAL_FILES=$((END_NUM - START_NUM + 1))
        ;;
    5)
        echo "é€€å‡ºä¸‹è½½"
        exit 0
        ;;
    *)
        echo "æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨ç¨³å®šæ¨¡å¼"
        PARALLEL_JOBS=1
        ;;
esac

# è®¾ç½®èµ·å§‹å’Œç»“æŸç‚¹
START_NUM=${START_NUM:-0}
END_NUM=${END_NUM:-1822}

echo ""
echo "=== ä¸‹è½½é…ç½® ==="
echo "èµ·å§‹æ–‡ä»¶: shard_$(printf "%05d" $START_NUM).parquet"
echo "ç»“æŸæ–‡ä»¶: shard_$(printf "%05d" $END_NUM).parquet"
echo "æ–‡ä»¶èŒƒå›´: $START_NUM - $END_NUM (å…± $TOTAL_FILES ä¸ªæ–‡ä»¶)"
echo "å¹¶è¡Œä»»åŠ¡: $PARALLEL_JOBS"

read -p "ç¡®è®¤å¼€å§‹ä¸‹è½½? (y/N): " confirm
if [ "$confirm" != "y" ] && [ "$confirm" != "Y" ]; then
    echo "å–æ¶ˆä¸‹è½½"
    exit 0
fi

# å¼€å§‹ä¸‹è½½
echo ""
echo "=== ğŸš€ å¼€å§‹ä¸‹è½½ $(date) ===" | tee -a "$LOG_FILE"

# åˆ›å»ºä¸‹è½½å‡½æ•°
download_file() {
    local file_index=$1
    local filename=$(printf "shard_%05d.parquet" $file_index)
    local filepath="$BASE_DATA_DIR/$filename"
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
    if [ -f "$filepath" ] && [ -s "$filepath" ]; then
        echo "âœ… $filename å·²å­˜åœ¨ï¼Œè·³è¿‡" | tee -a "$LOG_FILE"
        return 0
    fi
    
    echo "ğŸ“¥ å¼€å§‹ä¸‹è½½ $filename..." | tee -a "$LOG_FILE"
    local start_time=$(date +%s)
    
    # ä¸‹è½½æ–‡ä»¶
    if hf download --repo-type dataset karpathy/fineweb-edu-100b-shuffle "$filename" --local-dir "$BASE_DATA_DIR" 2>>"$LOG_FILE"; then
        local end_time=$(date +%s)
        local duration=$((end_time - start_time))
        local size=$(du -h "$filepath" | cut -f1)
        echo "âœ… $filename å®Œæˆ (${duration}s, ${size})" | tee -a "$LOG_FILE"
        return 0
    else
        echo "âŒ $filename å¤±è´¥" | tee -a "$LOG_FILE"
        # æ¸…ç†å¤±è´¥çš„æ–‡ä»¶
        rm -f "$filepath" 2>/dev/null
        return 1
    fi
}

# å¯¼å‡ºå‡½æ•°ä»¥ä¾›å¹¶è¡Œä½¿ç”¨
export -f download_file
export BASE_DATA_DIR LOG_FILE HF_ENDPOINT

# å¹¶è¡Œä¸‹è½½
if [ "$PARALLEL_JOBS" -gt 1 ]; then
    echo "ä½¿ç”¨ $PARALLEL_JOBS ä¸ªå¹¶è¡Œä»»åŠ¡ä¸‹è½½..."
    seq $START_NUM $END_NUM | xargs -n 1 -P $PARALLEL_JOBS -I {} bash -c 'download_file {}'
else
    echo "é€ä¸ªä¸‹è½½æ–‡ä»¶..."
    for i in $(seq $START_NUM $END_NUM); do
        download_file $i
        
        # æ¯ä¸‹è½½10ä¸ªæ–‡ä»¶æ˜¾ç¤ºè¿›åº¦
        if [ $((i % 10)) -eq 0 ]; then
            completed=$((i - START_NUM + 1))
            percentage=$((completed * 100 / TOTAL_FILES))
            echo "ğŸ“Š è¿›åº¦: $completed/$TOTAL_FILES ($percentage%)" | tee -a "$LOG_FILE"
        fi
    done
fi

# æœ€ç»ˆç»Ÿè®¡
echo ""
echo "=== ğŸ“Š ä¸‹è½½å®Œæˆç»Ÿè®¡ $(date) ===" | tee -a "$LOG_FILE"

final_files=$(ls "$BASE_DATA_DIR"/*.parquet 2>/dev/null | wc -l)
total_size=$(du -sh "$BASE_DATA_DIR" 2>/dev/null | cut -f1)

echo "æœ€ç»ˆæ–‡ä»¶æ•°: $final_files" | tee -a "$LOG_FILE"
echo "æ€»å¤§å°: $total_size" | tee -a "$LOG_FILE"

if [ $final_files -eq $TOTAL_FILES ]; then
    echo "ğŸ‰ æ­å–œï¼æ‰€æœ‰æ–‡ä»¶ä¸‹è½½å®Œæˆï¼" | tee -a "$LOG_FILE"
else
    missing=$((TOTAL_FILES - final_files))
    echo "âš ï¸  è¿˜æœ‰ $missing ä¸ªæ–‡ä»¶æœªå®Œæˆ" | tee -a "$LOG_FILE"
    echo "å¯ä»¥é‡æ–°è¿è¡Œæ­¤è„šæœ¬è¿›è¡Œæ–­ç‚¹ç»­ä¼ " | tee -a "$LOG_FILE"
fi

# éªŒè¯æ•°æ®
echo ""
echo "=== ğŸ” æ•°æ®éªŒè¯ ==="
python3 -c "
import pandas as pd
import os
import random

base_data_dir = '$BASE_DATA_DIR'
files = sorted([f for f in os.listdir(base_data_dir) if f.endswith('.parquet')])

print(f'éªŒè¯ {len(files)} ä¸ªæ–‡ä»¶...')

# éšæœºæ£€æŸ¥å‡ ä¸ªæ–‡ä»¶
sample_files = random.sample(files, min(5, len(files)))
total_rows = 0

for filename in sample_files:
    filepath = os.path.join(base_data_dir, filename)
    try:
        df = pd.read_parquet(filepath)
        rows = len(df)
        total_rows += rows
        print(f'âœ… {filename}: {rows:,} è¡Œ')
    except Exception as e:
        print(f'âŒ {filename}: éªŒè¯å¤±è´¥ - {e}')

print(f'\\næŠ½æ ·éªŒè¯å®Œæˆï¼Œå¹³å‡æ¯æ–‡ä»¶çº¦ {total_rows // len(sample_files):,} è¡Œ')
print('ğŸ‰ æ•°æ®é›†å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹å¤§è§„æ¨¡è®­ç»ƒï¼')
"

echo ""
echo "=== ğŸ“‹ ä¸‹ä¸€æ­¥å»ºè®® ==="
echo "1. æ£€æŸ¥ç£ç›˜ç©ºé—´: df -h"
echo "2. æŸ¥çœ‹æ—¥å¿—: tail -f $LOG_FILE"
echo "3. å¼€å§‹è®­ç»ƒ: ./debug_simple_train.sh"
echo "4. åˆ†ææ•°æ®: python parquet_analysis.py"

echo ""
echo "ğŸš€ FineWeb å®Œæ•´æ•°æ®é›†ä¸‹è½½ä»»åŠ¡å®Œæˆï¼"