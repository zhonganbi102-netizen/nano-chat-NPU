#!/bin/bash

# FineWebæ•°æ®é›†ä¸‹è½½è„šæœ¬ - NPUä¼˜åŒ–ç‰ˆ
# ä¸‹è½½200ä¸ªæ–‡ä»¶è¿›è¡Œå®Œæ•´è®­ç»ƒ

set -e

echo "=== FineWebæ•°æ®é›†ä¸‹è½½è„šæœ¬ ==="

# è®¾ç½®ç¯å¢ƒ
export HF_ENDPOINT=https://hf-mirror.com

# æ£€æŸ¥ç£ç›˜ç©ºé—´
echo "=== æ£€æŸ¥ç£ç›˜ç©ºé—´ ==="
df -h
echo ""

# è·å–å¯ç”¨ç©ºé—´ (GB)
available_space=$(df -BG . | awk 'NR==2 {print $4}' | sed 's/G//')
echo "å½“å‰å¯ç”¨ç©ºé—´: ${available_space}GB"

# ä¼°ç®—æ‰€éœ€ç©ºé—´ (æ¯ä¸ªæ–‡ä»¶çº¦100-200MBï¼Œ200ä¸ªæ–‡ä»¶çº¦20-40GB)
required_space=50
if [ "$available_space" -lt "$required_space" ]; then
    echo "âŒ ç£ç›˜ç©ºé—´ä¸è¶³ï¼éœ€è¦è‡³å°‘${required_space}GBï¼Œå½“å‰åªæœ‰${available_space}GB"
    echo "è¯·æ¸…ç†ç£ç›˜ç©ºé—´åé‡è¯•"
    exit 1
fi

# åˆ›å»ºæ•°æ®ç›®å½•
echo "=== åˆ›å»ºæ•°æ®ç›®å½• ==="
mkdir -p ./base_data
cd ./base_data

# æ£€æŸ¥å·²ä¸‹è½½æ–‡ä»¶
existing_files=$(ls shard_*.parquet 2>/dev/null | wc -l || echo "0")
echo "å·²å­˜åœ¨æ–‡ä»¶æ•°é‡: $existing_files"

# è®¾ç½®ä¸‹è½½å‚æ•°
total_files=200
start_shard=5
end_shard=$((start_shard + total_files - 1))
concurrent_downloads=3  # é™ä½å¹¶å‘æ•°é¿å…ç½‘ç»œæ‹¥å µ

echo "=== å¼€å§‹ä¸‹è½½FineWebæ•°æ®é›† ==="
echo "ç›®æ ‡æ–‡ä»¶æ•°é‡: $total_files"
echo "æ–‡ä»¶èŒƒå›´: shard_$(printf "%05d" $start_shard).parquet åˆ° shard_$(printf "%05d" $end_shard).parquet"
echo "å¹¶å‘ä¸‹è½½æ•°: $concurrent_downloads"
echo ""

# åˆ›å»ºä¸‹è½½è¿›åº¦æ–‡ä»¶
progress_file="download_progress.txt"
echo "0" > $progress_file

# å¹¶è¡Œä¸‹è½½å‡½æ•°
download_shard() {
    local shard_num=$1
    local filename=$(printf "shard_%05d.parquet" $shard_num)
    
    if [ -f "$filename" ]; then
        echo "â­ï¸  è·³è¿‡å·²å­˜åœ¨: $filename"
        return 0
    fi
    
    echo "ğŸ“¥ å¼€å§‹ä¸‹è½½: $filename"
    
    # ä½¿ç”¨é‡è¯•æœºåˆ¶
    local max_retries=3
    local retry=0
    
    while [ $retry -lt $max_retries ]; do
        if hf download --repo-type dataset karpathy/fineweb-edu-100b-shuffle "$filename" --local-dir . 2>/dev/null; then
            echo "âœ… å®Œæˆ: $filename"
            
            # æ›´æ–°è¿›åº¦
            local current_progress=$(cat $progress_file)
            echo $((current_progress + 1)) > $progress_file
            local total_downloaded=$(cat $progress_file)
            local percentage=$((total_downloaded * 100 / total_files))
            echo "ğŸ“Š è¿›åº¦: $total_downloaded/$total_files ($percentage%)"
            
            return 0
        else
            retry=$((retry + 1))
            echo "âš ï¸  é‡è¯• $retry/$max_retries: $filename"
            sleep 2
        fi
    done
    
    echo "âŒ å¤±è´¥: $filename (å·²é‡è¯•$max_retriesæ¬¡)"
    return 1
}

# å¯¼å‡ºå‡½æ•°ä¾›xargsä½¿ç”¨
export -f download_shard
export progress_file
export total_files

# å¼€å§‹å¹¶è¡Œä¸‹è½½
echo "å¼€å§‹å¹¶è¡Œä¸‹è½½..."
seq $start_shard $end_shard | xargs -n 1 -P $concurrent_downloads -I {} bash -c 'download_shard {}'

# æ£€æŸ¥ä¸‹è½½ç»“æœ
echo ""
echo "=== ä¸‹è½½å®Œæˆæ£€æŸ¥ ==="
downloaded_count=$(ls shard_*.parquet 2>/dev/null | wc -l || echo "0")
echo "å®é™…ä¸‹è½½æ–‡ä»¶æ•°: $downloaded_count"

if [ "$downloaded_count" -ge 150 ]; then
    echo "âœ… ä¸‹è½½æˆåŠŸï¼å·²è·å¾—$downloaded_countä¸ªæ–‡ä»¶ï¼Œè¶³å¤Ÿè¿›è¡Œè®­ç»ƒ"
elif [ "$downloaded_count" -ge 100 ]; then
    echo "âš ï¸  éƒ¨åˆ†æˆåŠŸï¼šå·²è·å¾—$downloaded_countä¸ªæ–‡ä»¶ï¼Œå¯ä»¥è¿›è¡Œè®­ç»ƒä½†æ•°æ®é‡è¾ƒå°‘"
else
    echo "âŒ ä¸‹è½½ä¸è¶³ï¼šåªæœ‰$downloaded_countä¸ªæ–‡ä»¶ï¼Œå»ºè®®é‡æ–°è¿è¡Œæˆ–æ£€æŸ¥ç½‘ç»œ"
    exit 1
fi

# æ˜¾ç¤ºæ–‡ä»¶å¤§å°ç»Ÿè®¡
echo ""
echo "=== æ•°æ®é›†ç»Ÿè®¡ ==="
total_size=$(du -sh . | cut -f1)
echo "æ€»å¤§å°: $total_size"
echo "æ–‡ä»¶æ•°é‡: $downloaded_count"
echo "å¹³å‡æ–‡ä»¶å¤§å°: $(du -sm . | cut -f1 | awk -v count=$downloaded_count '{printf "%.1fMB", $1/count}')"

# æ¸…ç†è¿›åº¦æ–‡ä»¶
rm -f $progress_file

echo ""
echo "ğŸ‰ æ•°æ®é›†ä¸‹è½½å®Œæˆï¼"
echo "æ•°æ®ä½ç½®: $(pwd)"
echo "å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼š./train_with_fineweb.sh"
