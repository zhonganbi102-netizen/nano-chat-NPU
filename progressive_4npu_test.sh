#!/bin/bash

echo "ğŸ”¬ 4NPUæ¸è¿›å¼å†…å­˜æµ‹è¯•..."

# è®¾ç½®ç¯å¢ƒå˜é‡
export ASCEND_RT_VISIBLE_DEVICES=0,1,2,3
export WORLD_SIZE=4
export MASTER_ADDR=127.0.0.1
export MASTER_PORT=29500
export HCCL_WHITELIST_DISABLE=1
export HCCL_IF_IP=127.0.0.1
export PYTORCH_NPU_ALLOC_CONF="max_split_size_mb:512"

function cleanup_and_test() {
    echo "æ¸…ç†è¿›ç¨‹å’Œå†…å­˜..."
    pkill -f "python.*base_train.py" 2>/dev/null || true
    pkill -f "torchrun" 2>/dev/null || true
    sleep 3
    
    python3 -c "
import torch_npu
for i in range(4):
    try:
        torch_npu.npu.set_device(i)
        torch_npu.npu.empty_cache()
    except:
        pass
"
}

echo "=== æµ‹è¯•1: è¶…å°é…ç½® ==="
cleanup_and_test
echo "é…ç½®: depth=4, batch=2, seq_len=512"

torchrun --standalone --nproc_per_node=4 -- scripts/base_train.py \
    --depth=4 \
    --device_batch_size=2 \
    --total_batch_size=32768 \
    --max_seq_len=512 \
    --num_iterations=5 \
    --run="4npu_tiny_test"

if [ $? -eq 0 ]; then
    echo "âœ… è¶…å°é…ç½®æˆåŠŸ!"
    
    echo ""
    echo "=== æµ‹è¯•2: å°é…ç½® ==="
    cleanup_and_test
    echo "é…ç½®: depth=6, batch=3, seq_len=1024"
    
    torchrun --standalone --nproc_per_node=4 -- scripts/base_train.py \
        --depth=6 \
        --device_batch_size=3 \
        --total_batch_size=65536 \
        --max_seq_len=1024 \
        --num_iterations=5 \
        --run="4npu_small_test"
    
    if [ $? -eq 0 ]; then
        echo "âœ… å°é…ç½®æˆåŠŸ!"
        
        echo ""
        echo "=== æµ‹è¯•3: ä¸­é…ç½® ==="
        cleanup_and_test
        echo "é…ç½®: depth=8, batch=4, seq_len=1024"
        
        torchrun --standalone --nproc_per_node=4 -- scripts/base_train.py \
            --depth=8 \
            --device_batch_size=4 \
            --total_batch_size=131072 \
            --max_seq_len=1024 \
            --num_iterations=5 \
            --run="4npu_medium_test"
    else
        echo "âŒ å°é…ç½®å¤±è´¥"
    fi
else
    echo "âŒ è¶…å°é…ç½®å¤±è´¥ï¼Œå†…å­˜é—®é¢˜ä¸¥é‡"
fi

echo ""
echo "æµ‹è¯•å®Œæˆ: $(date)"