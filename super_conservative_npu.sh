#!/bin/bash

# è¶…çº§ä¿å®ˆå•NPUè®­ç»ƒè„šæœ¬ - ä¿®å¤æ‰€æœ‰NPUå…¼å®¹æ€§é—®é¢˜
# Super conservative single NPU training script - fixing all NPU compatibility issues

set -e

echo "=== è¶…çº§ä¿å®ˆå•NPUè®­ç»ƒ (ä¿®å¤ç‰ˆ) ==="
echo "Super Conservative Single NPU Training (Fixed Version)"

# 1. å¼ºåˆ¶æ¸…ç†çŽ¯å¢ƒ
echo "1. å¼ºåˆ¶æ¸…ç†NPUçŽ¯å¢ƒ..."
pkill -f python || echo "æ²¡æœ‰Pythonè¿›ç¨‹"
sleep 3

# æ¸…ç†ç³»ç»Ÿç¼“å­˜ï¼ˆå¦‚æžœæœ‰æƒé™ï¼‰
sync
echo 3 > /proc/sys/vm/drop_caches 2>/dev/null || echo "æ— æ³•æ¸…ç†ç³»ç»Ÿç¼“å­˜ï¼ˆéœ€è¦rootæƒé™ï¼‰"

# 2. è®¾ç½®NPUçŽ¯å¢ƒå˜é‡ - ä¸¥æ ¼éµå¾ªNPUè¦æ±‚
export ASCEND_RT_VISIBLE_DEVICES=0
export WORLD_SIZE=1
export RANK=0
export LOCAL_RANK=0
export MASTER_ADDR=127.0.0.1
export MASTER_PORT=29500

# NPUå†…å­˜é…ç½® - å¿…é¡» > 20MB
export PYTORCH_NPU_ALLOC_CONF=max_split_size_mb:128
export NPU_COMPILE_DISABLE=1
export TORCH_COMPILE_DISABLE=1

# è®¾ç½®AscendçŽ¯å¢ƒ
echo "2. è®¾ç½®AscendçŽ¯å¢ƒ..."
if [ -f "/usr/local/Ascend/ascend-toolkit/set_env.sh" ]; then
    source /usr/local/Ascend/ascend-toolkit/set_env.sh
    echo "âœ… æˆåŠŸåŠ è½½AscendçŽ¯å¢ƒ"
else
    echo "âš ï¸ æ‰‹åŠ¨è®¾ç½®AscendçŽ¯å¢ƒå˜é‡..."
    export ASCEND_HOME="/usr/local/Ascend/ascend-toolkit"
    export PATH="/usr/local/Ascend/ascend-toolkit/latest/bin:$PATH"
    export LD_LIBRARY_PATH="/usr/local/Ascend/ascend-toolkit/latest/lib64:$LD_LIBRARY_PATH"
    export PYTHONPATH="/usr/local/Ascend/ascend-toolkit/latest/python/site-packages:$PYTHONPATH"
fi

echo "é…ç½®è¯¦æƒ…:"
echo "  ä½¿ç”¨NPU: 0"
echo "  å†…å­˜åˆ†ç‰‡: 128MB (NPUè¦æ±‚ > 20MB)"
echo "  ç¼–è¯‘ä¼˜åŒ–: å®Œå…¨ç¦ç”¨"
echo "  ä¸–ç•Œå¤§å°: 1 (å•NPU)"

# 3. éªŒè¯NPUçŽ¯å¢ƒ
echo "3. éªŒè¯NPUçŽ¯å¢ƒ..."
python3 -c "
import torch
import torch_npu
import gc

print('éªŒè¯NPUçŽ¯å¢ƒ...')
if torch_npu.npu.is_available():
    print(f'âœ… NPUå¯ç”¨ï¼Œè®¾å¤‡æ•°é‡: {torch_npu.npu.device_count()}')
    
    # å¼ºåˆ¶æ¸…ç†NPUå†…å­˜
    for i in range(torch_npu.npu.device_count()):
        with torch_npu.npu.device(i):
            torch_npu.npu.empty_cache()
    gc.collect()
    
    # æ£€æŸ¥å½“å‰è®¾å¤‡
    device = torch_npu.npu.current_device()
    allocated = torch_npu.npu.memory_allocated(device) / 1024**3
    reserved = torch_npu.npu.memory_reserved(device) / 1024**3
    print(f'NPU {device}: å·²åˆ†é… {allocated:.2f} GiB, ä¿ç•™ {reserved:.2f} GiB')
else:
    print('âŒ NPUä¸å¯ç”¨')
    exit(1)
" || exit 1

# 4. åˆ›å»ºä¼˜åŒ–å™¨è¡¥ä¸ - é¿å…Muonï¼Œåªç”¨AdamW
echo "4. åˆ›å»ºNPUä¼˜åŒ–å™¨è¡¥ä¸..."
cat > npu_optimizer_patch.py << 'EOF'
import torch
import sys
import os

# ç¡®ä¿å¯ä»¥æ‰¾åˆ°nanochatæ¨¡å—
sys.path.insert(0, '.')

print("ðŸ”§ å¯¼å…¥nanochatæ¨¡å—...")
try:
    from nanochat.gpt import GPT
    print("âœ… GPTç±»å¯¼å…¥æˆåŠŸ")
except Exception as e:
    print(f"âŒ GPTç±»å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

def npu_safe_optimizers(self, unembedding_lr=0.001, embedding_lr=0.01, matrix_lr=0.01, weight_decay=0.0):
    """NPUå®‰å…¨çš„ä¼˜åŒ–å™¨å®žçŽ° - çº¯AdamW"""
    print("ðŸš€ NPUå®‰å…¨ä¼˜åŒ–å™¨: çº¯AdamWå®žçŽ°")
    
    try:
        # èŽ·å–æ‰€æœ‰å‚æ•°
        params = list(self.parameters())
        param_count = sum(p.numel() for p in params)
        
        print(f"  ðŸ“Š å‚æ•°ç»Ÿè®¡: {len(params)}ä¸ªå¼ é‡, {param_count:,}ä¸ªå‚æ•°")
        
        # ä½¿ç”¨å•ä¸€AdamWä¼˜åŒ–å™¨ï¼Œé¿å…å¤æ‚çš„å‚æ•°åˆ†ç»„
        optimizer = torch.optim.AdamW(
            params, 
            lr=max(embedding_lr, unembedding_lr, matrix_lr),  # ä½¿ç”¨æœ€å¤§å­¦ä¹ çŽ‡
            weight_decay=weight_decay,
            betas=(0.9, 0.95),  # ç¨å¾®è°ƒæ•´beta
            eps=1e-8,
            foreach=False,  # NPUå…¼å®¹æ€§
            fused=False,    # NPUå…¼å®¹æ€§
            amsgrad=False   # å…³é—­é¢å¤–åŠŸèƒ½
        )
        
        print(f"  âœ… NPU AdamWä¼˜åŒ–å™¨åˆ›å»ºæˆåŠŸ: lr={max(embedding_lr, unembedding_lr, matrix_lr)}")
        return [optimizer]
        
    except Exception as e:
        print(f"  âŒ ä¼˜åŒ–å™¨åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise

# åº”ç”¨è¡¥ä¸
try:
    print("ðŸ”§ åº”ç”¨NPUä¼˜åŒ–å™¨è¡¥ä¸...")
    GPT.setup_optimizers = npu_safe_optimizers
    print("âœ… NPUä¼˜åŒ–å™¨è¡¥ä¸å·²åº”ç”¨")
except Exception as e:
    print(f"âŒ è¡¥ä¸åº”ç”¨å¤±è´¥: {e}")
    sys.exit(1)
EOF

# 5. è®­ç»ƒtokenizerï¼ˆæœ€å°é…ç½®ï¼‰
echo "5. è®­ç»ƒtokenizerï¼ˆå¦‚æžœéœ€è¦ï¼‰..."
if [ ! -f ~/.cache/nanochat/tokenizer/tokenizer.pkl ]; then
    echo "è®­ç»ƒtokenizer..."
    python -m scripts.tok_train || echo "tokenizerè®­ç»ƒå¤±è´¥ï¼Œä½†ç»§ç»­..."
else
    echo "âœ… tokenizerå·²å­˜åœ¨"
fi

# 6. è¶…ä¿å®ˆè®­ç»ƒé…ç½®
echo "6. å¼€å§‹è¶…ä¿å®ˆè®­ç»ƒ..."
echo ""
echo "ðŸ“Š è®­ç»ƒé…ç½®:"
echo "  - æ¨¡åž‹æ·±åº¦: 4å±‚"
echo "  - è®¾å¤‡batch: 2"
echo "  - æ€»batch: 4096" 
echo "  - è®­ç»ƒæ­¥æ•°: 50æ­¥ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰"
echo "  - å­¦ä¹ çŽ‡: 0.001ï¼ˆä¿å®ˆï¼‰"
echo ""

# å¯¼å…¥è¡¥ä¸å¹¶è¿è¡Œè®­ç»ƒ
echo "å¯¼å…¥ä¼˜åŒ–å™¨è¡¥ä¸..."
python -c "
import npu_optimizer_patch
print('âœ… NPUè¡¥ä¸å¯¼å…¥æˆåŠŸ')
"

echo "å¼€å§‹è¶…ä¿å®ˆè®­ç»ƒ..."
python -m scripts.base_train \
    --run=super_conservative_npu \
    --depth=4 \
    --device_batch_size=2 \
    --total_batch_size=4096 \
    --num_iterations=50 \
    --embedding_lr=0.001 \
    --unembedding_lr=0.001 \
    --matrix_lr=0.001 \
    --weight_decay=0.01 \
    --grad_clip=1.0 \
    --eval_every=999999 \
    --sample_every=999999 \
    --core_metric_every=999999

# 7. æ¸…ç†
rm -f npu_optimizer_patch.py

echo ""
echo "ðŸŽ‰ è¶…ä¿å®ˆNPUè®­ç»ƒå®Œæˆï¼"
echo ""
echo "å¦‚æžœæˆåŠŸï¼Œå¯ä»¥é€æ­¥å¢žåŠ :"
echo "1. depth: 4 -> 6 -> 8"
echo "2. device_batch_size: 2 -> 4 -> 8"
echo "3. num_iterations: 50 -> 100 -> 500"